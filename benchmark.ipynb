{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AoShuang92/calibration_is_all_you_need/blob/main/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM0-fzshDuxQ",
        "outputId": "d5ea4e35-1a4a-4e78-f093-9e19faa46705"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import string\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "#NLP\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors, GloVe\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "#torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import math\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext import data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PByFEiMJvMNw",
        "outputId": "b093729d-aa97-464c-86da-b23110d03a19"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sJ09pMzGHOQ",
        "outputId": "3cc75e58-4197-484e-f870-31c21a574635"
      },
      "source": [
        "train_dir = \"/content/drive/MyDrive/calibration_project/sentiment_analysis/Tweets.csv\"\n",
        "df = pd.read_csv(train_dir)\n",
        "batch_size = 8\n",
        "max_length = 35\n",
        "def remove_unnecessary(text):\n",
        "    #remove_URL\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    text = url.sub('', text)\n",
        "\n",
        "    #remove_html\n",
        "    html = re.compile(r'<.*?>')\n",
        "    text = html.sub('', text)\n",
        "\n",
        "    #remove @\n",
        "    text = re.sub('@[^\\s]+','',text)\n",
        "\n",
        "    #remove_emoji\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "    #Removes integers \n",
        "    text = ''.join([i for i in text if not i.isdigit()])         \n",
        "    \n",
        "    #remove_punct\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(table)\n",
        "\n",
        "    #Replaces contractions from a string to their equivalents \n",
        "    contraction_patterns = [(r'won\\'t', 'will not'), (r'can\\'t', 'cannot'), (r'i\\'m', 'i am'), \n",
        "                            (r'ain\\'t', 'is not'), (r'(\\w+)\\'ll', '\\g<1> will'), (r'(\\w+)n\\'t', '\\g<1> not'),\n",
        "                            (r'(\\w+)\\'ve', '\\g<1> have'), (r'(\\w+)\\'s', '\\g<1> is'), (r'(\\w+)\\'re', '\\g<1> are'),\n",
        "                            (r'(\\w+)\\'d', '\\g<1> would'), (r'&', 'and'), (r'dammit', 'damn it'), \n",
        "                            (r'dont', 'do not'), (r'wont', 'will not')]\n",
        "    \n",
        "    patterns = [(re.compile(regex), repl) for (regex, repl) in contraction_patterns]\n",
        "    for (pattern, repl) in patterns:\n",
        "        text, _= re.subn(pattern, repl, text)\n",
        "\n",
        "\n",
        "\n",
        "    #lemmatize_sentence\n",
        "    sentence_words = text.split(' ')\n",
        "    new_sentence_words = list()\n",
        "    \n",
        "    for sentence_word in sentence_words:\n",
        "        sentence_word = sentence_word.replace('#', '')\n",
        "        new_sentence_word = WordNetLemmatizer().lemmatize(sentence_word.lower(), wordnet.VERB)\n",
        "        new_sentence_words.append(new_sentence_word)\n",
        "        \n",
        "    new_sentence = ' '.join(new_sentence_words)\n",
        "    new_sentence = new_sentence.strip()\n",
        "\n",
        "    return new_sentence\n",
        "\n",
        "\n",
        "def prepare_csv(df_train, seed=27, val_ratio=0.2):\n",
        "    idx = np.arange(df_train.shape[0])    \n",
        "    np.random.shuffle(idx)\n",
        "    val_size = int(len(idx) * val_ratio)\n",
        "    if not os.path.exists('cache'): # cache is tem memory file \n",
        "        os.makedirs('cache')\n",
        "    \n",
        "    df_train.iloc[idx[val_size:], :][['tweet_id', 'airline_sentiment', 'text']].to_csv(\n",
        "        'cache/dataset_train.csv', index=False)\n",
        "    \n",
        "    df_train.iloc[idx[:val_size], :][['tweet_id', 'airline_sentiment', 'text']].to_csv(\n",
        "        'cache/dataset_val.csv', index=False)    \n",
        "    \n",
        "def get_iterator(dataset, batch_size, train=True,\n",
        "                 shuffle=True, repeat=False, device=None): \n",
        "    dataset_iter = data.Iterator(\n",
        "        dataset, batch_size=batch_size, device=device,\n",
        "        train=train, shuffle=shuffle, repeat=repeat,\n",
        "        sort=False)  \n",
        "    return dataset_iter\n",
        "\n",
        "def get_dataset(fix_length=max_length, lower=False, vectors=None,train_dir = train_dir, batch_size=batch_size, device=None): \n",
        "    print('Preparing dataset...')\n",
        "    train = pd.read_csv(train_dir,error_bad_lines=False)\n",
        "    train['airline_sentiment'] = train['airline_sentiment'].map({\n",
        "    'positive': 0,\n",
        "    'negative': 1,\n",
        "    'neutral':2})\n",
        "    # labels = train['airline_sentiment'].tolist()\n",
        "    train['text'] = train['text'].apply(lambda x: remove_unnecessary(x))\n",
        "    \n",
        "    if vectors is not None:\n",
        "        lower=True\n",
        "    #to split dataset for train and validation\n",
        "    prepare_csv(train)\n",
        "    TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"spacy\"),init_token='<sos>',eos_token='<eos>',lower=True,batch_first=True, \n",
        "                      fix_length=fix_length)\n",
        "    \n",
        "    LABEL = data.Field(use_vocab=False, sequential=False, dtype=torch.float16)\n",
        "    ID = data.Field(use_vocab=False, sequential=False, dtype=torch.float16)   \n",
        "    train_temp, val_temp = data.TabularDataset.splits(\n",
        "        path='cache/', format='csv', skip_header=True,\n",
        "        train='dataset_train.csv', validation='dataset_val.csv',\n",
        "        fields=[('tweet_id', ID), ('airline_sentiment', LABEL), ('text', TEXT)])  \n",
        "  \n",
        "    TEXT.build_vocab(\n",
        "        train_temp, val_temp,\n",
        "        max_size=20000,\n",
        "        min_freq=10)\n",
        "        #vectors=GloVe(name='6B', dim=300) )\n",
        "    LABEL.build_vocab(train_temp)\n",
        "    ID.build_vocab(train_temp, val_temp)\n",
        "\n",
        "    word_embeddings = TEXT.vocab.vectors\n",
        "    ntokens = len(TEXT.vocab.stoi)\n",
        "    vocab_size = len(TEXT.vocab)\n",
        "    \n",
        "    train_loader = get_iterator(train_temp, batch_size=batch_size, \n",
        "                              train=True, shuffle=True,\n",
        "                              repeat=False,device=device)\n",
        "    test_loader = get_iterator(val_temp, batch_size=batch_size, \n",
        "                            train=True, shuffle=True,\n",
        "                            repeat=False, device=device)\n",
        "\n",
        "    print('Train samples:%d'%(len(train_temp)), 'Valid samples:%d'%(len(val_temp)),'Train minibatch nb:%d'%(len(train_loader)),\n",
        "          'Valid minibatch nb:%d'%(len(test_loader)), 'ntokens:%d'%(ntokens))\n",
        "    \n",
        "    return vocab_size, ntokens, word_embeddings, train_loader, test_loader\n",
        "\n",
        "vocab_size, ntokens, word_embeddings, train_loader, test_loader = get_dataset (fix_length=max_length, lower=False, vectors=None,train_dir = train_dir, batch_size=batch_size, device=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing dataset...\n",
            "Train samples:11712 Valid samples:2928 Train minibatch nb:1464 Valid minibatch nb:366 ntokens:1603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxPKjyhRGK0K"
      },
      "source": [
        "def create_masks(sentence):\n",
        "    \n",
        "    sentence_mask = sentence!=0\n",
        "    sentence_mask = sentence_mask.to(device)\n",
        "    sentence_mask = sentence_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
        "     \n",
        "    return sentence_mask \n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(max_length, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len]\n",
        "    return data, target\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements embeddings of the words and adds their positional encodings. \n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, max_len = max_length):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def create_positinal_encoding(self, max_len, d_model):\n",
        "        pe = torch.zeros(max_len, d_model).to(device)\n",
        "        for pos in range(max_len):   # for each position of the word\n",
        "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "        pe = pe.unsqueeze(0)   # include the batch size\n",
        "        return pe\n",
        "        \n",
        "    def forward(self, encoded_words):\n",
        "        embedding = self.embed(encoded_words) * math.sqrt(self.d_model)\n",
        "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
        "        embedding = self.dropout(embedding)\n",
        "        return embedding\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self, heads, d_model):\n",
        "        \n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % heads == 0\n",
        "        self.d_k = d_model // heads\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.query = nn.Linear(d_model, d_model)\n",
        "        self.key = nn.Linear(d_model, d_model)\n",
        "        self.value = nn.Linear(d_model, d_model)\n",
        "        self.concat = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        query, key, value of shape: (batch_size, max_len, 512)\n",
        "        mask of shape: (batch_size, 1, 1, max_words)\n",
        "        \"\"\"\n",
        "        # (batch_size, max_len, 512)\n",
        "        query = self.query(query)\n",
        "        key = self.key(key)        \n",
        "        value = self.value(value)   \n",
        "        \n",
        "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n",
        "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
        "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
        "        \n",
        "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
        "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
        "        #scores = torch.matmul(query, key.permute(2,1,0,0)) / math.sqrt(query.size(-1))\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n",
        "        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n",
        "        weights = self.dropout(weights)\n",
        "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        context = torch.matmul(weights, value)\n",
        "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
        "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
        "        # (batch_size, max_len, h * d_k)\n",
        "        interacted = self.concat(context)\n",
        "        return interacted\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, middle_dim = 2048):\n",
        "        super(FeedForward, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
        "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.fc1(x))\n",
        "        out = self.fc2(self.dropout(out))\n",
        "        return out\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, mask):\n",
        "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
        "        interacted = self.layernorm(interacted + embeddings)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        encoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return encoded\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, heads):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
        "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
        "        query = self.layernorm(query + embeddings)\n",
        "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
        "        interacted = self.layernorm(interacted + query)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        decoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return decoded\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):    \n",
        "    def __init__(self, d_model, heads, num_layers, ntokens):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = ntokens\n",
        "        self.embed = Embeddings(self.vocab_size, d_model)#max_len\n",
        "        #self.embed_dec = Embeddings(self.vocab_size, d_model,max_length)\n",
        "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "        #self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "        self.logit = nn.Linear(max_length*self.d_model, 3)   \n",
        "        \n",
        "    def encode(self, src_words, src_mask):\n",
        "        src_embeddings = self.embed(src_words)\n",
        "        for layer in self.encoder:\n",
        "            src_embeddings = layer(src_embeddings, src_mask)\n",
        "        return src_embeddings\n",
        "    \n",
        "    # def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
        "    #     tgt_embeddings = self.embed_dec(target_words)\n",
        "    #     for layer in self.decoder:\n",
        "    #         tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
        "    #     return tgt_embeddings\n",
        "        \n",
        "    def forward(self, src_words, src_mask):\n",
        "        encoded = self.encode(src_words, src_mask)\n",
        "        #decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
        "        #out = F.log_softmax(self.logit(encoded), dim = 2)\n",
        "        encoded = encoded.view(batch_size,-1)\n",
        "        out = self.logit(encoded)\n",
        "        return out\n",
        "\n",
        "class AdamWarmup:\n",
        "    \n",
        "    def __init__(self, model_size, warmup_steps, optimizer):\n",
        "        \n",
        "        self.model_size = model_size\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer = optimizer\n",
        "        self.current_step = 0\n",
        "        self.lr = 0\n",
        "        \n",
        "    def get_lr(self):\n",
        "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
        "        \n",
        "    def step(self):\n",
        "        # Increment the number of steps each time we call the step function\n",
        "        self.current_step += 1\n",
        "        lr = self.get_lr()\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        # update the learning rate\n",
        "        self.lr = lr\n",
        "        self.optimizer.step()\n",
        "\n",
        "class LossWithLS(nn.Module):\n",
        "\n",
        "    def __init__(self, size, smooth):\n",
        "        super(LossWithLS, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
        "        self.confidence = 1.0 - smooth\n",
        "        self.smooth = smooth\n",
        "        self.size = size\n",
        "        \n",
        "    def forward(self, prediction, target, mask):\n",
        "        \"\"\"\n",
        "        prediction of shape: (batch_size, max_words, vocab_size)\n",
        "        target and mask of shape: (batch_size, max_words)\n",
        "        \"\"\"\n",
        "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
        "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
        "        mask = mask.float()\n",
        "        mask = mask.view(-1)       # (batch_size * max_words)\n",
        "        labels = prediction.data.clone()\n",
        "        labels.fill_(self.smooth / (self.size - 1))\n",
        "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n",
        "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
        "        return loss\n",
        "\n",
        "def seed_everything(seed=27):\n",
        "  #random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IATn-BfHKkvh"
      },
      "source": [
        "def train(train_loader, transformer, criterion, epoch,optim):    \n",
        "    transformer.train()\n",
        "    sum_loss = 0\n",
        "    count = 0\n",
        "    for i, pair in enumerate(train_loader): \n",
        "        input = pair.text.to(device)\n",
        "        target = pair.airline_sentiment.to(device)\n",
        "\n",
        "        input_mask = create_masks(input)\n",
        "        out = transformer(input, input_mask )\n",
        "        loss = criterion(out, target.long())\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "\n",
        "def valid (test_loader,transformer): \n",
        "    transformer.eval()\n",
        "    sum_loss = 0\n",
        "    sum_acc = 0\n",
        "\n",
        "    for i, pair in enumerate(test_loader): \n",
        "\n",
        "        input = pair.text.to(device)\n",
        "        target = pair.airline_sentiment.to(device)\n",
        "\n",
        "        input_mask = create_masks(input)\n",
        "        out = transformer(input, input_mask)\n",
        "        loss = criterion(out, target.long())\n",
        "        sum_loss += loss.item()\n",
        "        num_corrects = (torch.max(out, 1)[1].view(target.size()).data == target.data).float().sum()\n",
        "        acc = 100.0 * num_corrects / batch_size\n",
        "        sum_acc += acc.item()\n",
        "    return sum_loss/len(test_loader) ,  sum_acc/len(test_loader)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oXEK081c7Tb"
      },
      "source": [
        "class _ECELoss(nn.Module):\n",
        "    def __init__(self, n_bins=15):\n",
        "        \"\"\"\n",
        "        n_bins (int): number of confidence interval bins\n",
        "        \"\"\"\n",
        "        super(_ECELoss, self).__init__()\n",
        "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
        "        self.bin_lowers = bin_boundaries[:-1]\n",
        "        self.bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    def forward(self, logits, labels):\n",
        "        softmaxes = F.softmax(logits, dim=1)\n",
        "        confidences, predictions = torch.max(softmaxes, 1)\n",
        "        accuracies = predictions.eq(labels)\n",
        "        ece = torch.zeros(1, device=logits.device)\n",
        "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
        "            # Calculated |confidence - accuracy| in each bin\n",
        "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
        "            prop_in_bin = in_bin.float().mean()\n",
        "            if prop_in_bin.item() > 0:\n",
        "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "\n",
        "        return ece\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wubcM3ac8Se",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "6d2608ab-878e-4694-dd99-74e05fa50dfc"
      },
      "source": [
        "seed_everything()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "d_model = 512\n",
        "heads = 8\n",
        "num_layers = 3\n",
        "lr = 1e-4\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Transformer(d_model = d_model, heads = heads, num_layers = num_layers, ntokens = ntokens)\n",
        "model = model.to(device)\n",
        "#adam_optimizer = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
        "#transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "best_acc = 0\n",
        "best_epoch = 0\n",
        "for epoch in range(10):\n",
        "    train(train_loader, model, criterion, epoch,optim)\n",
        "    loss, acc = valid (test_loader,model)\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_epoch = epoch\n",
        "        state = {'epoch': epoch, 'transformer': model, 'transformer_optimizer': transformer_optimizer}\n",
        "        torch.save(state, '/content/drive/MyDrive/calibration_project/sentiment_analysis/best_base_model_object.pth.tar')\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/calibration_project/sentiment_analysis/best_base_model_object.pth')\n",
        "    print('cur epoch:%d, cur acc:%.5f, best epoch:%d, best acc:%.5f'%(epoch,acc, best_epoch, best_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cur epoch:0, cur acc:72.95082, best epoch:0, best acc:72.95082\n",
            "cur epoch:1, cur acc:74.93169, best epoch:1, best acc:74.93169\n",
            "cur epoch:2, cur acc:77.25410, best epoch:2, best acc:77.25410\n",
            "cur epoch:3, cur acc:75.64891, best epoch:2, best acc:77.25410\n",
            "cur epoch:4, cur acc:71.27732, best epoch:2, best acc:77.25410\n",
            "cur epoch:5, cur acc:74.11202, best epoch:2, best acc:77.25410\n",
            "cur epoch:6, cur acc:72.71175, best epoch:2, best acc:77.25410\n",
            "cur epoch:7, cur acc:71.44809, best epoch:2, best acc:77.25410\n",
            "cur epoch:8, cur acc:75.34153, best epoch:2, best acc:77.25410\n",
            "cur epoch:9, cur acc:75.47814, best epoch:2, best acc:77.25410\n",
            "cur epoch:10, cur acc:76.33197, best epoch:2, best acc:77.25410\n",
            "cur epoch:11, cur acc:75.34153, best epoch:2, best acc:77.25410\n",
            "cur epoch:12, cur acc:74.35109, best epoch:2, best acc:77.25410\n",
            "cur epoch:13, cur acc:73.29235, best epoch:2, best acc:77.25410\n",
            "cur epoch:14, cur acc:73.42896, best epoch:2, best acc:77.25410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-61a24327b847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-74649fb42f63>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, transformer, criterion, epoch, optim)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#transformer_optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVFaQCwzVzhS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}